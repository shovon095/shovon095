<div id="badges" align="center">
<a href="mailto:shouvonsarker@gmail.com">
<img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/>
</a>
<a href="https://www.google.com/search?q=https://linkedin.in/shouvon-sarker">
<img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
</a>
<a href="https://scholar.google.com/citations?user=WGTZTE8AAAAJ&hl=en">
<img src="https://img.shields.io/badge/Google_Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white" alt="Google Scholar"/>
</a>
<a href="cv/ShouvonSarker_CV.pdf">
<img src="https://img.shields.io/badge/Download_CV-FF5733?style=for-the-badge&logo=Acrobat&logoColor=white" alt="CV"/>
</a>
</div>

<h1 align="center">
Shouvon Sarker
</h1>

About Me
I am a Ph.D. candidate in Electrical Engineering with a research focus on Large Language Models (LLMs) for complex natural language and data-driven applications. My work is centered on building transparent, trustworthy, and efficient AI systems for mission-critical domains, including Earth Science and Clinical NLP.

My core research interests include:

Explainable AI & Knowledge Distillation: Developing methods to make black-box models transparent and interpretable.

Textâ€‘toâ€‘SQL for Scientific Databases: Translating natural language questions into executable database queries for NASA's Earth Science data archives.

Clinical NLP: Extracting and classifying medication events from electronic health records to improve patient safety.

Generative AI & Trustworthiness: Building robust frameworks for generating and detecting machine-generated text, as recognized by the NIST GenAI Challenge.

News
August 2024: Our work on a generator-detector framework for trustworthy text generation placed in the Top 10% at the NIST GenAI 2024 Challenge.

June 2024: Presented our research, "Enhancing LLM Fine-Tuning for Text-to-SQL by SQL Quality Measurement," at IJCNN 2024.

August 2023: My paper, "Ensemble BERT for Medication Event Classification on EHRs," was published at the International Conference on Intelligent Biology and Medicine (ICIBM 2023).

Technologies & Skills
Languages: Python, C/C++, SQL, HTML/CSS, PHP

Deep Learning: PyTorch, TensorFlow, Keras, Hugging Face Transformers

LLM & GenAI: LangChain, PEFT, LoRA, Parameter-Efficient Fine-Tuning, OpenAI API

Data Science: Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn

DevOps & Databases: Git, Docker, Linux, AWS, MySQL, PostgreSQL

Simulation: MATLAB, NetSim, GNS3

Featured Projects
NASA DEAP-SQL: A self-discovery Text-to-SQL pipeline that improves query generation accuracy by over 3% through automated SQL quality refinement. ğŸ”— View on GitHub

Attention-Enhanced Text-to-SQL: Integrates a non-parametric attention mechanism with an LLM to boost Text-to-SQL accuracy by 10% without requiring external knowledge. ğŸ”— View on GitHub

Actor-Critic GenAI Framework: A generator and detector system for trustworthy text generation, which placed in the Top 10% at the NIST GenAI 2024 Challenge. ğŸ”— View on GitHub

SJS-Distill-NER: A novel structured knowledge distillation method using Jensen-Shannon divergence to align token and transition probabilities for Named Entity Recognition. ğŸ”— View on GitHub

Ensemble-BERT for Med Events: An ensemble of BERT models for classifying medication events in Electronic Health Records, published at ICIBM 2023. ğŸ”— View on GitHub

GitHub Statistics
<p align="center">
<img src="https://github-readme-stats.vercel.app/api?username=shovon095&show_icons=true&theme=tokyonight&hide_border=true&count_private=true&rank_icon=github" alt="shovon095's GitHub Stats" />
<br/>
<img src="https://github-readme-stats.vercel.app/api/top-langs/?username=shovon095&layout=compact&theme=tokyonight&hide_border=true" alt="shovon095's Top Languages" />
</p>

Academic Background
<details>
<summary><strong>Education</strong></summary>
<br>

Ph.D. in Electrical Engineering | Prairie View A&M University (2023 â€“ Present)

GPA: 4.0/4.0

Research: Large Language Models, Explainable AI, Text2SQL

M.S. in Electrical Engineering | Prairie View A&M University (2021 â€“ 2022)

GPA: 3.90/4.0

Thesis: Ensemble BERT for Medication Events Classification

B.Sc. in Electronics and Communication Engineering (ECE) | KUET, Bangladesh (2014 â€“ 2018)

Thesis: Performance Analysis of Narrowband Cognitive Radio Network

</details>

<details>
<summary><strong>Publications</strong></summary>
<br>

Peer-Reviewed Publications
Dong, X., Sarker, S., & Qian, L. (2022). â€œIntegrating Humanâ€‘inâ€‘theâ€‘Loop into Swarm Learning for Decentralized Fake News Detection.â€ Proc. IDSTA 2022.

Dong, X., Fu, Y., Kuo, M., Sarker, S., et al. (2024). â€œEnhancing Deep Knowledge Tracing via Diffusion Models for Personalized Adaptive Learning.â€ ASEE Annual Conf. 2024.

Sarker, S., Dong, X., & Qian, L. (2023). â€œEnsemble BERT for Medication Event Classification on EHRs.â€ ICIBM 2023.

Sarker, S., Li, X., & Dong, X. (2023). â€œMedical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Event Classification.â€ IEEE BHI 2023.

Sarker, S., Dong, X., & Qian, L. (2025). â€œText Generator and Text Discriminator for NIST GenAI T2T Challenge.â€ AIRC 2025.

Manuscripts Under Review or In Preparation
â€œEnhancing LLM Fineâ€‘Tuning for Textâ€‘toâ€‘SQL by SQL Quality Measurement,â€ submitted to IJCNN 2024.

â€œIntegrating Nonâ€‘Parametric Attention to Enhance LLMâ€‘Based Textâ€‘toâ€‘SQL Without External Knowledge.â€

â€œFrom Tokens to Transitions: A Structured Jensenâ€“Shannon Knowledge Distillation Method for NER.â€

</details>
